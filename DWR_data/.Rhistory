))
}
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 3)
summary(data)
debug(generateData)
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 3)
generateData <- function(n=100000, pscore.type = 1) {
cov1 <- runif(n, min = 0.01, max = 0.9)
cov2 <- runif(n, min = 0.1, max = 0.9)
cov3 <- rnorm(n, mean = .50, sd = .5)
cov4 <- rnorm(n, mean = 1, sd = .5)
#if (pscore.type == 0) {treat <- rbinom(n, 1, 0.05)}  #5% treatment
if (pscore.type == 1) {treat1 <- rbinom(n, 1, 0.1)}  #10% treatment
if (pscore.type == 2) {treat1 <- rbinom(n, 1, 0.2)}  #20% treatment
if (pscore.type == 3) {treat1 <- rbinom(n, 1, 0.5)}  #50% treatment
if (pscore.type == 4) {treat1 <- rbinom(n, 1, 0.8)}  #80% treatment
#################################################################################################################################
treat2 <- ifelse(treat1 == 1, 1, rbinom(n, 1, 0.05))
treat3 <- ifelse(treat2 == 1, 1, rbinom(n, 1, 0.05))
#################################################################################################################################
Y0_1 = rnorm(n, mean = (-.5 + 1.9*(cov1)  - cov2 + (1.3*cov3)*(cov4)), sd=1.5)
Y1_1 = rnorm(n, mean = (-.5 + 2.1*(cov1)  - cov2 + (1.3*cov3)*(cov4)), sd=1)
Y0_2 = rnorm(n, mean = 1.2*(Y0_1), sd=1.5)
Y1_2 = rnorm(n, mean = 1.2*(Y1_1), sd=1)
Y0_3 = rnorm(n, mean = 1.2*(Y0_2), sd=1.5)
Y1_3 = rnorm(n, mean = 1.2*(Y1_2), sd=1)
Y_observe1 <-  ifelse(treat1 == 1, Y1_1, Y0_1)  #observed outcome year1
Y_observe2 <-  ifelse(treat2 == 1, Y1_2, Y0_2)  #observed outcome year2
Y_observe3 <-  ifelse(treat3 == 1, Y1_3, Y0_3)  #observed outcome year3
return(data.frame(cov1,cov2,cov3,cov4,
treat1, treat2, treat3,
Y_observe1, Y1_1, Y0_1,
Y_observe2, Y1_2, Y0_2,
Y_observe3, Y1_3, Y0_3
))
}
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 3)
summary(data)
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 2)
summary(data)
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 1)
summary(data)
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 4)
summary(data)
# load packages
library(tidyverse)
library(lubridate)
setwd("C:/Users/jcf2d/Box Sync/__Workshops/DataWranglingInR")
setwd("stocks")
setwd("DWR_01_data")
setwd("stocks")
# TIP: look at one of the CSV files before starting. Do you need to use the .id
# argument?
setwd("../doe")
grads <- list.files()
grads
grads_df <- lapply(grads, read_csv)
grads_df <- bind_rows(grads_df)
table(grads_df$SCHOOL_YEAR)
# Let's create some fake data to demonstrate merging/joining data:
left <- data.frame(id=c(2:5),
x=c(90, 93, 99, 89))
left
right <- data.frame(id=rep(1:4,each=2),
y=c("a", "d", "e", "c", "e", "d", "a", "b"))
right
# If we want to retain everything in the left data frame and merge only what
# has a matching id in the right data frame, we do a LEFT JOIN.
left_join(left, right, by = "id")
# If we want to retain everything in the right data frame and merge only what
# has a matching id in the left data frame, we do a RIGHT JOIN.
right_join(left, right, by = "id")
# If we want to retain only those rows with matching ids in both data sets, we
# do an INNER JOIN.
inner_join(left, right, by = "id")
# If we wanted to merge all rows regardless of match, we do a FULL JOIN.
full_join(left, right, by = "id")
# Sometimes we have more than one key in each data frame that we want to merge
# on. In that case we give the by argument a vector of keys
dat11 <- tibble(REGION = c(1,1,2,2),
STATE = c(1,2,1,2),
x = runif(4))
dat11
dat12 <- tibble(REGION = c(1,2,3),
STATE = c(2,1,1),
y = c("a","b","c"))
dat12
# left join
left_join(dat11, dat12, by = c("REGION", "STATE"))
dat11 <- tibble(id1 = c(1,1,2,2),
id2 = c(1,2,1,2),
x = runif(4))
dat11
dat12 <- tibble(REGION = c(1,2,3),
STATE = c(2,1,1),
y = c("a","b","c"))
dat12
left_join(dat11, dat12, by = c("id1" = "REGION", "id2" = "STATE"))
ex01 <- tibble(id = 1:5,
name = c("Rick", "Morty", "Jerry", "Beth", "Summer"),
age = c(67, 15, 42, 39, 17))
ex01
ex02 <- tibble(ID = 1:3,
GRP = c(1, 1, 2))
ex02
# all rows in ex01 that have a match in ex02
semi_join(ex01, ex02, by = c("id" = "ID"))
# all rows in ex01 that do NOT have a match in ex02
anti_join(ex01, ex02, by = c("id" = "ID"))
# set working directory up one level
setwd("..")
# read in historical stock data for Apple (obtained from Yahoo Finance)
aapl <- read_csv("AAPL.csv")
aapl$Date <- mdy(aapl$Date)
# read in Google trends data for "new macbook pro 2018"
gt <- read_csv("mac_book_pro_trends.csv",
skip = 3,
col_names = c("Date","Interest"))
View(gt)
View(aapl)
# Let's merge the stock data with the Google Trends data. It appears we can
# merge on Date.
names(aapl)
names(gt)
# However all stock data is Monday - Friday while Google trends data is weekly
# on Sunday. No records in common by Date so inner_join returns an empty data
# frame.
inner_join(aapl, gt, by = "Date")
# Change google trends date to Monday by adding 1
gt$Date <- gt$Date + 1
# Perform inner join to merge records from both data frames with matching dates,
# and save as a new data frame.
aapl_gt <- inner_join(aapl, gt, by = "Date")
glimpse(aapl_gt)
str(aapl_gt)
head(aapl_gt)
# Is there any association between google trends and closing price? Plot Closing
# Price vs Interest and add a smooth trend line
ggplot(aapl_gt, aes(x = Interest, y = Close)) +
geom_point() +
geom_smooth(se = F)
# How many records in gt have a match in aapl?
# Use semi_join and "Pipe" the result into nrow() using %>%
# Tip: Use Ctrl + Shift + M (or Cmd + Shift + M) to enter %>%
semi_join(gt, aapl, by = "Date") %>% nrow()
# How many records in aapl do NOT have a match in gt?
anti_join(aapl, gt, by = "Date") %>% nrow()
# Read in school population totals for all Virginia schools for the 2016-2017
# year
va_schools  <- read_csv("va_schools_2016-2017.csv")
names(va_schools)
# remove non-alpha-numeric characters from column names
# ^[:alnum:] = NOT alpha-umeric
names(va_schools) <- str_remove_all(names(va_schools), "[^[:alnum:]]")
# Convert division and school numbers to character with leading 0s
va_schools$DivNo <- str_pad(string = va_schools$DivNo,
width = 3, side = "left", pad = 0)
va_schools$SchoolNo <- str_pad(string = va_schools$SchoolNo,
width = 4, side = "left", pad = 0)
# subset grads_df to only include rows where SCHOOL_YEAR == "2016-2017"
grads_df_2016_2017 <- filter(grads_df, SCHOOL_YEAR == "2016-2017")
# 1) Merge the grads_df_2016_2017 and va_schools data frames based on Division
# and School Number such that all rows from grads_df_2016_2017 are retained.
# Save the new data frame as va2016_2017
names(grads_df_2016_2017)
names(va_schools)
names(va_schools)[c(1,3)]
# 1) Merge the grads_df_2016_2017 and va_schools data frames based on Division
# and School Number such that all rows from grads_df_2016_2017 are retained.
# Save the new data frame as va2016_2017
names(grads_df_2016_2017)[c(3,5)]
names(va_schools)[c(1,3)]
va2016_2017 <- left_join(grads_df_2016_2017, va_schools,
by = c("DIV_NUM" = "DivNo",
"SCH_NUM" = "SchoolNo"))
# With this combined data, we can look at, say, schools with the highest rate of
# economically disadvantaged completers.
va2016_2017 %>%
mutate(pctComplete = HS_COMPLETER_CNT/Grade12) %>%
filter(!is.na(FEDERAL_RACE_CODE) & !is.na(GENDER) &
!is.na(DISABILITY_FLAG) & !is.na(LEP_FLAG) &
!is.na(DISADVANTAGED_FLAG)) %>%
filter(DISADVANTAGED_FLAG == "Y") %>%
arrange(desc(pctComplete)) %>%
select(SCH_NAME, GENDER, HS_COMPLETER_CNT, Grade12, pctComplete) %>%
head(n=20)
stocks_df
setwd("stocks")
# get file names
stocks <- list.files()
# apply read_csv to each file name; return a list
stocks_ls <- lapply(stocks, read_csv)
# name each list element (replace ".csv" with nothing)
names(stocks_ls) <- sub(".csv", "", stocks)
# Use bind_rows to combine all data frames in list to one data frame.
# Use the .id argument to add a column indicating the stock
stocks_df <- bind_rows(stocks_ls, .id = "stock")
# Convert Date to actual date value using lubridate's dmy() function
stocks_df$Date <- dmy(stocks_df$Date)
# plot closing price over time for all stocks
ggplot(stocks_df, aes(x = Date, y = Close, color = stock)) +
geom_line()
stocks_df
stocks_df_long <- gather(stocks_df, key = price_type, value = price, Open:Close)
head(stocks_df_long)
# With our data in "long" format we can create plots like this:
ggplot(filter(stocks_df_long, price_type %in% c("High","Low")),
aes(x = Date, y = price, color = price_type)) +
geom_line() +
facet_wrap(~stock, scales = "free")
View(aapl_gt)
# get file names
stocks <- list.files()
# apply read_csv to each file name; return a list
stocks_ls <- lapply(stocks, read_csv)
names(stocks_ls)
stocks
str_replace(stocks, ".csv", "")
# name each list element (replace ".csv" with nothing)
names(stocks_ls) <- str_replace(stocks, ".csv", "")
# Release dates, run times and box office gross of the Marvel Cinematic
# Universe.
# https://en.wikipedia.org/wiki/List_of_Marvel_Cinematic_Universe_films
mcu <- read.csv("http://people.virginia.edu/~jcf2d/data/marvel_movies.csv",
stringsAsFactors = FALSE)
str(mcu)
# Use the parse_number() function from the readr() package to format the
# box_office as numeric.
mcu$box_office <- parse_number(mcu$box_office)
mcu
# Let's fix our Marvel movie dates
head(mcu$release_date) # day-month-year, or dmy
mcu$release_date <- dmy(mcu$release_date)
str(mcu)
head(as.numeric(mcu$release_date))
# How can we format the run times of the Marvel movies?
head(mcu$run_time)
# Notice hm, ms or hms does not work:
hm(mcu$run_time)
ms(mcu$run_time)
hms(mcu$run_time)
# The "min" is not parsing; we could replace " min" with ":00" and then use ms()
mcu$run_time2 <- str_replace(mcu$run_time, " min", ":00")
mcu$run_time2
mcu$run_time2 <- ms(mcu$run_time2)
mcu$run_time2
as.numeric(mcu$run_time2)
# An easier way is to use the period and duration functions.
duration(mcu$run_time)
period(mcu$run_time)
# some quick summary stats
table(mcu$month)
# Let's add the day of the week, month, and year of the movie release as columns
# to the mcu data frame:
mcu <- mcu %>% mutate(day = wday(mcu$release_date, label = TRUE, abbr = FALSE),
month = month(mcu$release_date, label = TRUE, abbr = FALSE),
year = year(mcu$release_date))
mcu
# some quick summary stats
table(mcu$month)
# total box office by year
bo_total <- mcu %>%
group_by(year) %>%
summarize(totalBoxOffice = sum(box_office))
bo_total
# visualize total box office by year
ggplot(bo_total, aes(x = year, y = totalBoxOffice)) +
geom_point() +
geom_line() +
scale_x_continuous(breaks = 2008:2018) +
scale_y_continuous(labels = scales::dollar) +
theme(panel.grid.minor.x = element_blank()) +
ggtitle("Total MCU Box Office by Year") +
labs(x = "Year", y = "Total Box Office")
# Let's revisit the run times of the marvel movies
mcu$run_time
# Notice we can specify these directly as durations
duration(mcu$run_time)
# Further, notice we can specify the duration as periods:
as.period(duration(mcu$run_time))
# And this yields a more human-friendly version of run time. Let's save to our
# data frame.
mcu$run_time2 <- as.period(duration(mcu$run_time))
mcu %>% select(movie, run_time, run_time2)
# Let's calculate time between marvel movie releases and convert to months.
int_diff(mcu$release_date)
time_length(int_diff(mcu$release_date), unit = "months")
# To add to the mcu data frame, we need to add a missing field to the beginning
# of the vector.
mcu$release_interval <- c(NA, time_length(int_diff(mcu$release_date), unit = "months"))
mcu %>%
select(movie, release_date, release_interval)
# examine time between releases
summary(mcu$release_interval)
View(mcu)
View(stocks_df)
View(grads_df)
table(grads_df$DIV_NAME)
setwd("..")
dat01 <- tibble(x = 1:5, y = 5:1)
dat01
dat02 <- tibble(x = 10:16, y = x/2)
dat02
dat03 <- tibble(z = runif(5)) # 5 random numbers from interval (0,1)
dat03
# stack dat01 and dat02
bind_rows(dat01, dat02)
# save the new stacked data frame
dat04 <- bind_rows(dat01, dat02)
dat04
# we can use the same data frames multiple times
bind_rows(dat01, dat02, dat01)
# Example of binding data frames with no matching columns.
bind_rows(dat01, dat03)
# We can use the optional ".id" argument to create a new column that contains an
# identifier for the original data.
bind_rows(dat01, dat02, .id = "id")
# Naming the data frames that we're binding provides a useful label in the id
# column.
bind_rows("dat01" = dat01, "dat02" = dat02, .id = "id")
# bind_rows() also works on lists of data frames
list01 <- list("dat01" = dat01, "dat02" = dat02)
list01
bind_rows(list01)
bind_rows(list01, .id = "source")
# pace dat01 and dat03 side-byside
bind_cols(dat01, dat03)
setwd("stocks")
# get file names
stocks <- list.files()
# apply read_csv to each file name; return a list
stocks_ls <- lapply(stocks, read_csv)
# name each list element (replace ".csv" with nothing)
names(stocks_ls) <- str_replace(stocks, ".csv", "")
# Use bind_rows to combine all data frames in list to one data frame.
# Use the .id argument to add a column indicating the stock
stocks_df <- bind_rows(stocks_ls, .id = "stock")
# Convert Date to actual date value using lubridate's dmy() function
stocks_df$Date <- dmy(stocks_df$Date)
# plot closing price over time for all stocks
ggplot(stocks_df, aes(x = Date, y = Close, color = stock)) +
geom_line()
rm(list = c(paste0("dat0",1:4), "list01"))
names(stocks_ls)
day(stocks_df$Date)
wday(stocks_df$Date)
wday(stocks_df$Date, label = TRUE)
# Extract day of week
stocks_df$Day <- wday(stocks_df$Date, label = TRUE)
View(stocks_df)
setwd("C:/Users/jcf2d/Desktop/cps")
load("C:/Users/jcf2d/Desktop/cps/data.Rdata")
library(dplyr)
library(haven)
summary(data)
summary(data$AHRSWORKT)
str(data$AHRSWORKT)
levels(data$AHRSWORKT)
data$AHRSWORKTN <- as.numeric(as.character(data$AHRSWORKT))
summary(data$AHRSWORKTN)
hist(data$AHRSWORKTN)
data %>%
group_by(YEAR, MARST, SEX) %>%
summarize(AvgHrsWeek = weighted.mean(x = AHRSWORKTN, w = ASECWT, na.rm = TRUE))
data %>%
group_by(YEAR, MARST, SEX) %>%
summarize(AvgHrsWeek = weighted.mean(x = AHRSWORKTN, w = ASECWT, na.rm = TRUE)) %>%
as.data.frame()
data %>%
group_by(YEAR, MARST, SEX) %>%
filter(MARST != "NIU") %>%
summarize(AvgHrsWeek = weighted.mean(x = AHRSWORKTN, w = ASECWT, na.rm = TRUE)) %>%
as.data.frame()
data %>%
group_by(YEAR, MARRIED, CHILDREN) %>%
filter(MARST != "NIU") %>%
summarize(AvgHrsWeek = weighted.mean(x = AHRSWORKTN, w = ASECWT, na.rm = TRUE)) %>%
as.data.frame()
str(data)
length(interaction(with(dat, c(YEAR, MARST))))
length(interaction(with(data, c(YEAR, MARST))))
levels(data$MARST)
filter(data, !MARST %in% c("Widowed or Divorced", "NIU"))
class(data)
summary(data)
summary(data$MONTH)
setwd("C:/Users/jcf2d/Box Sync/__Workshops/DataWranglingInR")
setwd("stocks")
setwd("C:/Users/jcf2d/Box Sync/__Workshops/DataWranglingInR/DWR_01_data")
setwd("stocks")
# get file names
stocks <- list.files()
# apply read_csv to each file name; return a list
stocks_ls <- lapply(stocks, read_csv)
# name each list element (replace ".csv" with nothing)
names(stocks_ls) <- str_replace(stocks, ".csv", "")
# Use bind_rows to combine all data frames in list to one data frame.
# Use the .id argument to add a column indicating the stock
stocks_df <- bind_rows(stocks_ls, .id = "stock")
# Convert Date to actual date value using lubridate's dmy() function
stocks_df$Date <- dmy(stocks_df$Date)
# Extract day of week and save into new column called "Day"
stocks_df$Day <- wday(stocks_df$Date, label = TRUE)
mday(stocks_df$Date, label = TRUE)
mday(stocks_df$Date)
month(stocks_df$Date)
month(stocks_df$Date, label = TRUE)
stocks_df$Month <- month(stocks_df$Date, label = TRUE)
# plot closing price over time for all stocks
ggplot(stocks_df, aes(x = Date, y = Close, color = stock)) +
geom_line()
stocks_df %>%
group_by(Day) %>%
summarize(AvgVol = mean(Volume))
stocks_df %>%
group_by(Day) %>%
summarize(AvgVol = mean(Volume),
MedVol = median(Volume))
ggplot(stocks_df, aes(x = Day, y = Volume)) +
geom_point() +
facet_wrap(~stock)
ggplot(stocks_df, aes(x = Day, y = Volume)) +
geom_boxplot() +
facet_wrap(~stock)
ggplot(stocks_df, aes(x = Day, y = Volume)) +
geom_boxplot()
# plot closing price over time for all stocks
ggplot(stocks_df, aes(x = Date, y = Close, color = stock)) +
geom_line()
ggplot(stocks_df, aes(x = Date, y = Close, color = stock)) +
geom_line() +
facet_wrap(~Day)
# set working directory up one level
setwd("..")
# read in historical stock data for Apple (obtained from Yahoo Finance)
aapl <- read_csv("AAPL.csv")
summary(aapl)
head(aapl$Date)
# format date
aapl$Date <- mdy(aapl$Date)
# read in Google trends data for "new macbook pro 2018"
gt <- read_csv("mac_book_pro_trends.csv",
skip = 3,
col_names = c("Date","Interest"))
summary(gt)
str(gt)
str(gt)
str(aapl)
# read in historical stock data for Apple (obtained from Yahoo Finance)
aapl <- read_csv("AAPL.csv")
str(aapl)
summary(aapl)
head(aapl$Date)
# read in Google trends data for "new macbook pro 2018"
gt <- read_csv("mac_book_pro_trends.csv",
skip = 3,
col_names = c("Date","Interest"))
summary(gt)
# Let's merge the stock data with the Google Trends data. It appears we can
# merge on Date.
names(aapl)
names(gt)
# However all stock data is Monday - Friday while Google trends data is weekly
# on Sunday. No records in common by Date so inner_join returns an empty data
# frame.
inner_join(aapl, gt, by = "Date")
wday(aapl$Date, label = TRUE)
# format date
aapl$Date <- mdy(aapl$Date)
wday(aapl$Date, label = TRUE)
aapl$Day <- wday(aapl$Date, label = TRUE)
# add Day column
gt$Day <- wday(gt$Date, label = TRUE)
# Let's merge the stock data with the Google Trends data. It appears we can
# merge on Date.
names(aapl)
names(gt)
inner_join(aapl, gt, by = "Date")
table(aapl$Day)
table(gt$Day)
table(aapl$Day)
table(gt$Day)
# Change google trends date to Monday by adding 1
gt$Date <- gt$Date + 1
table(gt$Day)
gt$Day <- wday(gt$Date, label = TRUE)
table(gt$Day)
# Perform inner join to merge records from both data frames with matching dates,
# and save as a new data frame.
aapl_gt <- inner_join(aapl, gt, by = "Date")
head(aapl_gt)
# Perform inner join to merge records from both data frames with matching dates,
# and save as a new data frame.
aapl_gt <- inner_join(aapl, gt, by = c("Date","Day"))
head(aapl_gt)
# Is there any association between google trends and closing price? Plot Closing
# Price vs Interest and add a smooth trend line
ggplot(aapl_gt, aes(x = Interest, y = Close)) +
geom_point() +
geom_smooth(se = F)
# How many records in gt have a match in aapl?
# Use semi_join and "Pipe" the result into nrow() using %>%
# Tip: Use Ctrl + Shift + M (or Cmd + Shift + M) to enter %>%
semi_join(gt, aapl, by = "Date") %>% nrow()
# How many records in aapl do NOT have a match in gt?
anti_join(aapl, gt, by = "Date") %>% nrow()
