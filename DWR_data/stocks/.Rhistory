mutate(prior      = prior      / sum(prior),
likelihood = likelihood / sum(likelihood)) %>%
# plot!
ggplot(aes(x = p_water)) +
geom_line(aes(y = prior), linetype = 2) +
geom_line(aes(y = likelihood)) +
scale_x_continuous("proportion water", breaks = c(0, .5, 1))
d %>%
expand(nesting(n_trials, toss, n_success),
p_water = seq(from = 0, to = 1, length.out = sequence_length)) %>%
group_by(p_water) %>%
# you can learn more about lagging here: https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/lag or here: https://dplyr.tidyverse.org/reference/lead-lag.html
mutate(lagged_n_trials  = lag(n_trials,  k = 1),
lagged_n_success = lag(n_success, k = 1)) %>%
ungroup() %>%
mutate(prior      = ifelse(n_trials == 1, .5,
dbinom(x    = lagged_n_success,
size = lagged_n_trials,
prob = p_water)),
likelihood = dbinom(x    = n_success,
size = n_trials,
prob = p_water),
strip      = str_c("n = ", n_trials)
) %>%
# the next three lines allow us to normalize the prior and the likelihood,
# putting them both in a probability metric
group_by(n_trials) %>%
mutate(prior      = prior      / sum(prior),
likelihood = likelihood / sum(likelihood)) %>%
# plot!
ggplot(aes(x = p_water)) +
geom_line(aes(y = prior), linetype = 2) +
geom_line(aes(y = likelihood)) +
scale_x_continuous("proportion water", breaks = c(0, .5, 1)) +
scale_y_continuous("plausibility", breaks = NULL)
d %>%
expand(nesting(n_trials, toss, n_success),
p_water = seq(from = 0, to = 1, length.out = sequence_length)) %>%
group_by(p_water) %>%
# you can learn more about lagging here: https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/lag or here: https://dplyr.tidyverse.org/reference/lead-lag.html
mutate(lagged_n_trials  = lag(n_trials,  k = 1),
lagged_n_success = lag(n_success, k = 1)) %>%
ungroup() %>%
mutate(prior      = ifelse(n_trials == 1, .5,
dbinom(x    = lagged_n_success,
size = lagged_n_trials,
prob = p_water)),
likelihood = dbinom(x    = n_success,
size = n_trials,
prob = p_water),
strip      = str_c("n = ", n_trials)
) %>%
# the next three lines allow us to normalize the prior and the likelihood,
# putting them both in a probability metric
group_by(n_trials) %>%
mutate(prior      = prior      / sum(prior),
likelihood = likelihood / sum(likelihood)) %>%
# plot!
ggplot(aes(x = p_water)) +
geom_line(aes(y = prior), linetype = 2) +
geom_line(aes(y = likelihood)) +
scale_x_continuous("proportion water", breaks = c(0, .5, 1)) +
scale_y_continuous("plausibility", breaks = NULL) +
theme(panel.grid = element_blank())
d %>%
expand(nesting(n_trials, toss, n_success),
p_water = seq(from = 0, to = 1, length.out = sequence_length)) %>%
group_by(p_water) %>%
# you can learn more about lagging here: https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/lag or here: https://dplyr.tidyverse.org/reference/lead-lag.html
mutate(lagged_n_trials  = lag(n_trials,  k = 1),
lagged_n_success = lag(n_success, k = 1)) %>%
ungroup() %>%
mutate(prior      = ifelse(n_trials == 1, .5,
dbinom(x    = lagged_n_success,
size = lagged_n_trials,
prob = p_water)),
likelihood = dbinom(x    = n_success,
size = n_trials,
prob = p_water),
strip      = str_c("n = ", n_trials)
) %>%
# the next three lines allow us to normalize the prior and the likelihood,
# putting them both in a probability metric
group_by(n_trials) %>%
mutate(prior      = prior      / sum(prior),
likelihood = likelihood / sum(likelihood)) %>%
# plot!
ggplot(aes(x = p_water)) +
geom_line(aes(y = prior), linetype = 2) +
geom_line(aes(y = likelihood)) +
scale_x_continuous("proportion water", breaks = c(0, .5, 1)) +
scale_y_continuous("plausibility", breaks = NULL) +
theme(panel.grid = element_blank()) +
facet_wrap(~strip, scales = "free_y")
tmp <- d %>%
expand(nesting(n_trials, toss, n_success),
p_water = seq(from = 0, to = 1, length.out = sequence_length)) %>%
group_by(p_water) %>%
# you can learn more about lagging here: https://www.rdocumentation.org/packages/stats/versions/3.5.1/topics/lag or here: https://dplyr.tidyverse.org/reference/lead-lag.html
mutate(lagged_n_trials  = lag(n_trials,  k = 1),
lagged_n_success = lag(n_success, k = 1)) %>%
as.data.frame()
library(brms)
install.packages("brms")
library(brms)
View(all)
View(d)
str(d)
mod <- brm(toss ~ 1, data = d, family = binomial(link = "identity"), prior = prior(beta(1, 1), class = Intercept))
d$toss <- as.numeric(d$toss=="w")
d
mod <- brm(toss ~ 1, data = d, family = binomial(link = "identity"), prior = prior(beta(1, 1), class = Intercept))
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
.Call("rs_canBuildCpp")
rstudioapi::buildToolsCheck()
file <- normalizePath(tempfile(fileext = ".c"), winslash = "/")
writeLines("void test() {}", con = file)
R <- file.path(R.home("bin"), "R")
system2(R, c("CMD", "SHLIB", shQuote(file)))
unlink(file)
remove.packages("rstan")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
pkgbuild::has_build_tools(debug = TRUE)
log(2) + log(2)
2 * 2
prod(1.09, 1.21, 1.34)
log(1.09) + log(1.21) + log(1.34)
log(1.09 + 1.21 + 1.34)
prod(2)
prod(3)
prod(5)
tibble(a   = runif(12, 0, 0.5),
b   = 1) %>%
mutate(c = a + b) %>%
summarise(p = prod(c) %>% log())
library(tidyverse)
tibble(a   = runif(12, 0, 0.5),
b   = 1) %>%
mutate(c = a + b) %>%
summarise(p = prod(c) %>% log())
tibble(a   = runif(12, 0, 0.5),
b   = 1)
tibble(a   = runif(12, 0, 0.5),
b   = 1) %>%
mutate(c = a + b)
install.packages("emmeans")
library(tidyverse)
version
n <- 160
gender <- sample(c(0,1), size = n, replace = TRUE)
tt <- sample(c(0,1), size = n, replace = TRUE)
rank <- factor(sample(c("Asst","Assoc","Prof"), size = n, replace = TRUE))
perf <- round(runif(n, min = 1, max = 5),2)
salary <- 45000 + 15000*tt + 7000*(rank=="Assoc") + 15000*(rank=="prof") + 1000*perf + rnorm(n, sd = 5000)
dat <- data.frame(gender, tt, rank, perf, salary)
write.csv(dat, file = "fakedata.csv", row.names = FALSE)
dat <- data.frame(gender, tt, rank, perf, salary = round(salary))
write.csv(dat, file = "fakedata.csv", row.names = FALSE)
install.packages("sjstats")
install.packages(c("bayestestR", "blogdown", "bootnet", "dbplyr", "deldir", "DT", "ellipsis", "emmeans", "ggplot2", "ggpubr", "mime", "mvtnorm", "plotrix", "qgraph", "R.utils", "RcppArmadillo", "readtext", "remotes", "rlang", "servr", "sjmisc", "StanHeaders", "tinytex", "visreg", "xfun"))
library(dataMaid)
data("toyData", package = "dataMaid")
toyData
makeDataReport(toyData, output = "html", render = FALSE,
openResult = FALSE, replace = TRUE)
?getFromNamespace
0.96*264
binom.test(x = 253, n = 264, conf.level = 0.95)
binom.test(x = 253, n = 264)
binom.test(100,100)
binom.test(x = 12, n = 20, p = 0.50)
binom.test(x = 117, n = 118)
binom.test(x = 118, n = 118)
prop.test(x = 117, n = 118)
binom.test(x = 117, n = 118)
prop.test(x = 118, n = 118)
binom.test(x = 0, n = 118)
binom.test(x = 0, n = 118)
binom.test(x = c(111,114,115), n = c(118,118,118))
x <- c(111,112,110,118)
n <- rep(118,4)
mapply(binom.test, x, n)
out <- mapply(binom.test, x, n)
out[[1]]
b_ci <- function(x,n)
{
binom.test(x,n)$conf.int
}
out <- mapply(b_ci, x, n)
out
library(effects)
mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion,
data=Cowles, family=binomial)
eff.cowles <- allEffects(mod.cowles, xlevels=list(extraversion=seq(0, 24, 6)),
fixed.predictors=list(given.values=c(sexmale=0.5)))
plot(eff.cowles)
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"))
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion")))
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion")))
Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion")
Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"))
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
)
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
xlevels=list(extraversion=seq(0, 24, 6))))
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
xlevels=list(extraversion=6)))
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
xlevels=list(extraversion=1)))
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
xlevels=list(extraversion=seq(24,24,1))))
Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
xlevels=list(extraversion=seq(24,24,1)))
e.out <- Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
xlevels=list(extraversion=seq(0, 24, 6)))
eDF <- as.data.frame(e.out)
View(eDF)
View(eDF)
seq(0, 24, 6)
library(ggplot2)
ggplot(subset(eDF, extraversion == 12),
aes(x = neuroticism, y = fit)) +
geom_line() +
geom_ribbon(aes(ylim = lower, ymax = upper), alpha = 1/3)
ggplot(subset(eDF, extraversion == 12),
aes(x = neuroticism, y = fit)) +
geom_line() +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1/3)
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
xlevels=list(extraversion=seq(0, 24, 6))))
ggplot(subset(eDF, extraversion == 12),
aes(x = neuroticism, y = fit)) +
geom_line() +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 1/3) +
ylim(c(0,1))
plot(Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
xlevels=list(extraversion=seq(0, 24, 6))))
e.out <- Effect(mod.cowles, focal.predictors = c("neuroticism","extraversion"),
xlevels=list(extraversion=seq(0, 24, 6),
neuroticism=seq(0, 24, 2)))
plot(e.out)
rbinom(n = 20, size = 20, prob = 0.5)
rbinom(n = 20, size = 20, prob = 0.5)
res <- rbinom(n = 20, size = 20, prob = 0.5)
res
sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5))
lapply(res, function(x)prop.test(x = x, n = 20, p = 0.5))
lapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value)
sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value)
sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
res <- rbinom(n = 20, size = 20, prob = 0.5)
mean(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
flip <- function(){
res <- rbinom(n = 20, size = 20, prob = 0.5)
sum(sapply(res, function(x)prop.test(x = x, n = 20, p = 0.5)$p.value) < 0.05)
}
out <- replicate(1000, expr = flip())
barplot(table(out))
prop.table(table(out))
mean(out > 0)
C1 <- sample(0:1, 100, replace = T)
C1 <- sample(0:1, 100, replace = T)
ifelse(C1==1,1,rbinom(n = 1, size = 1,prob = 0.05))
gd <- function(x){
C1 <- sample(0:1, 100, replace = T)
C2 <- ifelse(C1==1,1,rbinom(n = 1, size = 1,prob = x))
data.frame(C1,C2)
}
dat1 <- gd(x = 0.05)
dat2 <- gd(x = 0.25)
View(dat1)
generateData <- function(n=100000, pscore.type = 1) {
cov1 <- runif(n, min = 0.01, max = 0.9)
cov2 <- runif(n, min = 0.1, max = 0.9)
cov3 <- rnorm(n, mean = .50, sd = .5)
cov4 <- rnorm(n, mean = 1, sd = .5)
#if (pscore.type == 0) {treat <- rbinom(n, 1, 0.05)}  #5% treatment
if (pscore.type == 1) {treat1 <- rbinom(n, 1, 0.1)}  #10% treatment
if (pscore.type == 2) {treat1 <- rbinom(n, 1, 0.2)}  #20% treatment
if (pscore.type == 3) {treat1 <- rbinom(n, 1, 0.5)}  #50% treatment
if (pscore.type == 4) {treat1 <- rbinom(n, 1, 0.8)}  #80% treatment
#################################################################################################################################
if(pscore.type == 1 && treat1 == 1){treat2 = 1}
if(pscore.type == 1 && treat1 == 0){treat2 <- rbinom(n, 1, .05)}
if(pscore.type == 2 && treat1 == 1){treat2 = 1}
if(pscore.type == 2 && treat1 == 0){treat2 <- rbinom(n, 1, .05)}
if(pscore.type == 3 && treat1 == 1){treat2 = 1}
if(pscore.type == 3 && treat1 == 0){treat2 <- rbinom(n, 1, .05)}
if(pscore.type == 4 && treat1 == 1){treat2 = 1}
if(pscore.type == 4 && treat1 == 0){treat2 <- rbinom(n, 1, .05)}
if(pscore.type == 1 && treat2 == 1){treat3 = 1}
if(pscore.type == 1 && treat2 == 0){treat3 <- rbinom(n, 1, .05)}
if(pscore.type == 2 && treat2 == 1){treat3 = 1}
if(pscore.type == 2 && treat2 == 0){treat3 <- rbinom(n, 1, .05)}
if(pscore.type == 3 && treat2 == 1){treat3 = 1}
if(pscore.type == 3 && treat2 == 0){treat3 <- rbinom(n, 1, .05)}
if(pscore.type == 4 && treat2 == 1){treat3 = 1}
if(pscore.type == 4 && treat2 == 0){treat3 <- rbinom(n, 1, .05)}
#################################################################################################################################
Y0_1 = rnorm(n, mean = (-.5 + 1.9*(cov1)  - cov2 + (1.3*cov3)*(cov4)), sd=1.5)
Y1_1 = rnorm(n, mean = (-.5 + 2.1*(cov1)  - cov2 + (1.3*cov3)*(cov4)), sd=1)
Y0_2 = rnorm(n, mean = 1.2*(Y0_1), sd=1.5)
Y1_2 = rnorm(n, mean = 1.2*(Y1_1), sd=1)
Y0_3 = rnorm(n, mean = 1.2*(Y0_2), sd=1.5)
Y1_3 = rnorm(n, mean = 1.2*(Y1_2), sd=1)
Y_observe1 <-  ifelse(treat1 == 1, Y1_1, Y0_1)  #observed outcome year1
Y_observe2 <-  ifelse(treat2 == 1, Y1_2, Y0_2)  #observed outcome year2
Y_observe3 <-  ifelse(treat3 == 1, Y1_3, Y0_3)  #observed outcome year3
return(data.frame(cov1,cov2,cov3,cov4,
treat1, treat2, treat3,
Y_observe1, Y1_1, Y0_1,
Y_observe2, Y1_2, Y0_2,
Y_observe3, Y1_3, Y0_3
))
}
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 3)
summary(data)
debug(generateData)
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 3)
generateData <- function(n=100000, pscore.type = 1) {
cov1 <- runif(n, min = 0.01, max = 0.9)
cov2 <- runif(n, min = 0.1, max = 0.9)
cov3 <- rnorm(n, mean = .50, sd = .5)
cov4 <- rnorm(n, mean = 1, sd = .5)
#if (pscore.type == 0) {treat <- rbinom(n, 1, 0.05)}  #5% treatment
if (pscore.type == 1) {treat1 <- rbinom(n, 1, 0.1)}  #10% treatment
if (pscore.type == 2) {treat1 <- rbinom(n, 1, 0.2)}  #20% treatment
if (pscore.type == 3) {treat1 <- rbinom(n, 1, 0.5)}  #50% treatment
if (pscore.type == 4) {treat1 <- rbinom(n, 1, 0.8)}  #80% treatment
#################################################################################################################################
treat2 <- ifelse(treat1 == 1, 1, rbinom(n, 1, 0.05))
treat3 <- ifelse(treat2 == 1, 1, rbinom(n, 1, 0.05))
#################################################################################################################################
Y0_1 = rnorm(n, mean = (-.5 + 1.9*(cov1)  - cov2 + (1.3*cov3)*(cov4)), sd=1.5)
Y1_1 = rnorm(n, mean = (-.5 + 2.1*(cov1)  - cov2 + (1.3*cov3)*(cov4)), sd=1)
Y0_2 = rnorm(n, mean = 1.2*(Y0_1), sd=1.5)
Y1_2 = rnorm(n, mean = 1.2*(Y1_1), sd=1)
Y0_3 = rnorm(n, mean = 1.2*(Y0_2), sd=1.5)
Y1_3 = rnorm(n, mean = 1.2*(Y1_2), sd=1)
Y_observe1 <-  ifelse(treat1 == 1, Y1_1, Y0_1)  #observed outcome year1
Y_observe2 <-  ifelse(treat2 == 1, Y1_2, Y0_2)  #observed outcome year2
Y_observe3 <-  ifelse(treat3 == 1, Y1_3, Y0_3)  #observed outcome year3
return(data.frame(cov1,cov2,cov3,cov4,
treat1, treat2, treat3,
Y_observe1, Y1_1, Y0_1,
Y_observe2, Y1_2, Y0_2,
Y_observe3, Y1_3, Y0_3
))
}
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 3)
summary(data)
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 2)
summary(data)
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 1)
summary(data)
#################################################################################################################################
data <- generateData(n = 5000, pscore.type = 4)
summary(data)
library(leaflet)
leaflet() %>%
addProviderTiles("CartoDB")
apt <- read.table("/Users/jcf2d/Desktop/apartment_test.txt", header = F)
apt <- read.table("/Users/jcf2d/Desktop/apartment_test.txt", header = T)
apt <- read.table("/Users/jcf2d/Desktop/apartment_test.txt", header = T, stringsAsFactors = F)
View(apt)
apt$voucher <- c(1,1,1,0,0)
library(ggmap)
geocode(location = apt$Address)
# My Google Maps API key
# AIzaSyCT9Wn_TYsbc-lxNLBmddRtFuh_Z0Qpq2k
register_google(key = "AIzaSyCT9Wn_TYsbc-lxNLBmddRtFuh_Z0Qpq2k", write = TRUE)
geocode(location = apt$Address)
has_google_key()
google_key()
has_google_client()
has_google_signature()
# My Google Maps API key
# AIzaSyCT9Wn_TYsbc-lxNLBmddRtFuh_Z0Qpq2k
register_google(key = "AIzaSyCmB2Qund-PkTPiEyewDl87dBT3tFRCXFo", write = TRUE)
geocode(location = apt$Address)
geocode(location = apt$Address)
# My Google Maps API key
# AIzaSyCT9Wn_TYsbc-lxNLBmddRtFuh_Z0Qpq2k
register_google(key = "AIzaSyCmB2Qund-PkTPiEyewDl87dBT3tFRCXFo", write = TRUE)
apt <- read.table("/Users/jcf2d/Desktop/apartment_test.txt", header = T, stringsAsFactors = F)
apt$voucher <- c(1,1,1,0,0)
library(leaflet)
library(ggmap)
# My Google Maps API key
# AIzaSyCT9Wn_TYsbc-lxNLBmddRtFuh_Z0Qpq2k
register_google(key = "AIzaSyCmB2Qund-PkTPiEyewDl87dBT3tFRCXFo", write = TRUE)
geocode(location = apt$Address)
geocode(location = apt$Address)
lonlat <- geocode(location = apt$Address)
View(lonlat)
cbind(apt, lonlat)
lonlat <- geocode(location = apt$Address)
lonlat <- geocode(location = apt$Address)
View(apt)
register_google(key = "AIzaSyCmB2Qund-PkTPiEyewDl87dBT3tFRCXFo", write = TRUE)
lonlat <- geocode(location = apt$Address)
library(dplyr)
help("recode")
# load packages
library(tidyverse)
# load packages
library(tidyverse)
library(lubridate)
setwd("C:/Users/jcf2d/Box Sync/__Workshops/DataWranglingInR")
URL <- "http://people.virginia.edu/~jcf2d/data/DWR_01_data.zip"
d <- basename(URL)
download.file(url = URL, destfile = d)
download.file(url = URL, destfile = d)
unzip(d)
setwd("DWR_01_data")
rm(URL, d)
dat01 <- tibble(x = 1:5, y = 5:1)
dat01
dat02 <- tibble(x = 10:16, y = x/2)
dat02
dat03 <- tibble(z = runif(5)) # 5 random numbers from interval (0,1)
dat03
# stack dat01 and dat02
bind_rows(dat01, dat02)
# save the new stacked data frame
dat04 <- bind_rows(dat01, dat02)
dat04
# we can use the same data frames multiple times
bind_rows(dat01, dat02, dat01)
# Example of binding data frames with no matching columns.
bind_rows(dat01, dat03)
# We can use the optional ".id" argument to create a new column that contains an
# identifier for the original data.
bind_rows(dat01, dat02, .id = "id")
# Naming the data frames that we're binding provides a useful label in the id
# column.
bind_rows("dat01" = dat01, "dat02" = dat02, .id = "id")
# bind_rows() also works on lists of data frames
list01 <- list("dat01" = dat01, "dat02" = dat02)
list01
bind_rows(list01)
bind_rows(list01, .id = "source")
# pace dat01 and dat03 side-byside
bind_cols(dat01, dat03)
setwd("stocks")
# get file names
stocks <- list.files()
# apply read_csv to each file name; return a list
stocks_ls <- lapply(stocks, read_csv)
# name each list element (replace ".csv" with nothing)
names(stocks_ls) <- sub(".csv", "", stocks)
# Use bind_rows to combine all data frames in list to one data frame.
# Use the .id argument to add a column indicating the stock
stocks_df <- bind_rows(stocks_ls, .id = "stock")
# Convert Date to actual date value using lubridate's dmy() function
stocks_df$Date <- dmy(stocks_df$Date)
# plot closing price over time for all stocks
ggplot(stocks_df, aes(x = Date, y = Close, color = stock)) +
geom_line()
